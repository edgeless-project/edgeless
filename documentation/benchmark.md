# Benchmark tools

## edgeless_benchmark

`edgeless_benchmark` is a tool to help function developers and designers of
orchestration algorithms through the automated performance evaluation of a
population of workflows in controlled conditions.

The tool supports different arrival models and workflow types.

Arrival models (option `--arrival-model`):

| Arrival model | Description                                                                                                                                       |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| poisson       | Inter-arrival between consecutive workflows and lifetimes are exponentially distributed.                                                          |
| incremental   | One new workflow arrive every new inter-arrival time, with constant lifetime.                                                                     |
| incr-and-keep | Add workflows, with constant lifetimes, incrementally until the warm up period finishes, then keep until the end of the experiment.               |
| single        | Add a single workflow that lasts for the entire experiment.                                                                                       |
| trace         | Read the arrival and end times of workflows from a file specified with `--workload-trace`, one workflow per line in the format `arrival,end_time` |

Workflow types (option `--wf_type`):

| Workflow type    | Description                                                                                                                                                                                                                               | Template |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- |
| none             | No workflow is created. This option is meant only for testing/troubleshooting.                                                                                                                                                            | N        |
| single           | A single function.                                                                                                                                                                                                                        | N        |
| matrix-mul-chain | A chain of functions, each performing the multiplication of two matrices of 32-bit floating point random numbers at each invocation.                                                                                                      | Y        |
| vector-mul-chain | A chain of functions, each performing the multiplication of an internal random matrix of 32-bit floating point numbers by the input vector received from the caller.                                                                      | Y        |
| map-reduce       | A workflow consisting of a random number of stages, where each stage is composed of a random number of processing blocks. Before going to the next stage, the output from all the processing blocks in the stage before must be received. | Y        |
| json-spec        | The workflow specified in the given JSON file. The string `@WF_ID` in the file is substituted with a sequential identifier of the workflow.                                                                                               | N        |

For all the workflow types with Y in the template column a template can be generated by specifying `--wf-type "NAME;template"`.
For example, by running:

```shell
target/debug/edgeless_benchmark --wf-type "map-reduce;template" > map_reduce.json
```

A template will be generated in `map_reduce.json`, which can then be loaded with:

```shell
target/debug/edgeless_benchmark --wf-type "map-reduce;map_reduce.json"
```

The duration of the experiment is configurable via a command-line option,
like the seed used to generate pseudo-random numbers to enable repeatable
experiments.

## Dataset creation

The command `edgeless_benchmark` and the ε-ORC both support the option to save
run-time events during the execution for the purpose of creating a dataset from
an execution of the benchmark.
It is also possible to specify additional_fields

For `edgeleless_benchmark` this option is enabled by specifying a non-empty
value for option `--output`, which specifies where to save events.
The dataset files are encoded in a comma-separated values (CSV) format, with
the first row in each file containing the column names.
Each entry is pre-prended with additional fields, which can be specified with
the `--additional_fields`, corresponding to the additional header
`--additional_header`.
The output files are overwritten unless the `--append` option is provided.

For the ε-ORC configuration see the
[dedicated documentation page](./orchestrator.md).

### Step by step example

We assume that the repository has been downloaded and compiled in debug mode
(see [building instructions](../BUILDING.md)) and that a local instance of
Redis is running (see
[online instructions](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)).

First, build the `vector_mul.wasm` bytecode:

```bash
target/debug/edgeless_cli function build functions/vector_mul/function.json
```

Then, create the configuration files:

```bash
target/debug/edgeless_inabox -t
```

Modify the `[proxy]` section of `orchestrator.toml` as follows:

```ini
[proxy]
proxy_type = "Redis"
proxy_gc_period_seconds = 360
redis_url = "redis://127.0.0.1:6379"

[proxy.dataset_settings]
dataset_path = "dataset/myexp-"
append = true
additional_fields = "a,b"
additional_header = "h_a,h_b"
```

Enable performance samples on the node:

```shell
sed -i -e "s/performance_samples = false/performance_samples = true/" node.toml
```

In one shell start the EDGELESS in-a-box:

```bash
target/debug/edgeless_inabox
```

Then create the JSON file specifying the characteristics of the vector-mul-chain
workflow:

```shell
cat << EOF > vector_mul_chain.json
{
  "min_chain_length": 5,
  "max_chain_length": 5,
  "min_input_size": 1000,
  "max_input_size": 2000,
  "function_wasm_path": "functions/vector_mul/vector_mul.wasm"
}
EOF
```

In another run the following benchmark, which lasts 30 seconds:

```shell
target/debug/edgeless_benchmark \
    -w "vector-mul-chain;vector_mul_chain.json" \
    --output "dataset/output.csv" \
    --additional-fields "a,b" \
    --additional-header "h_a,h_b" \
    --lifetime 30 \
    --arrival-model incr-and-keep \
    --warmup 2 \
    --interarrival 1
```

The experiment lasts 30 seconds and creates 2 workflows.

The `dataset` directory now contains all the files in the table below,
starting with the prefix `myexp-`.

An example of a post-processing script is [included](examples-app-metrics.py):

```shell
MAPPING=dataset/myexp-mapping_to_instance_id.csv \
  SAMPLES=dataset/myexp-performance_samples.csv \
  python documentation/examples-app-metrics.py
```

Which gives something similar to this output:

```
losses:
1334f1a6-6531-4a46-ac80-82e1918a51a8: 0.0005299417064122947
b1ad77aa-3b6d-45eb-92cb-13c90f298f3d: 0.000727802037845706
latencies (mean, in ms):
1334f1a6-6531-4a46-ac80-82e1918a51a8: 15.200899615646799
b1ad77aa-3b6d-45eb-92cb-13c90f298f3d: 19.909612991821998
```
